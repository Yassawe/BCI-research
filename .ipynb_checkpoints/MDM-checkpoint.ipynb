{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env GEOMSTATS_BACKEND=numpy\n",
    "%env NUMEXPR_MAX_THREADS=12 \n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import geomstats.backend as gs\n",
    "import geomstats.geometry.spd_matrices as spd\n",
    "from geomstats.learning.frechet_mean import FrechetMean\n",
    "from scipy.stats import wilcoxon\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MDM:\n",
    "    def __init__(self, nchannels, metric):\n",
    "        self.nchannels = nchannels\n",
    "        self.n_classes = 2\n",
    "        self.means = np.zeros((2, nchannels, nchannels))\n",
    "        \n",
    "        if metric == \"Euclidean\":\n",
    "            self.Rmethod = None\n",
    "        elif metric == 'AIRM':\n",
    "            self.Rmethod = spd.SPDMetricAffine(n=self.nchannels)\n",
    "        elif metric == 'LEM':\n",
    "            self.Rmethod = spd.SPDMetricLogEuclidean(n=self.nchannels)\n",
    "        else:\n",
    "            raise Exception('Not implemented metric')\n",
    "        \n",
    "    def separate_classes(self, COV, Y):\n",
    "        classSpecificSPD=[]\n",
    "        for i in range(self.n_classes):\n",
    "            indecies = [j for j,val in enumerate(Y) if val==i]\n",
    "            classSPD = [COV[j] for j in indecies]\n",
    "            classSpecificSPD.append(classSPD)\n",
    "        return classSpecificSPD\n",
    "    \n",
    "    def calculate_means(self, classSpecificCOV):\n",
    "        if self.Rmethod is None:\n",
    "            class0_avg = sum(classSpecificCOV[0])/len(classSpecificCOV[0])\n",
    "            class1_avg = sum(classSpecificCOV[1])/len(classSpecificCOV[1])\n",
    "            return [class0_avg, class1_avg]\n",
    "        \n",
    "        estimator = FrechetMean(self.Rmethod, max_iter=64)\n",
    "        means = []\n",
    "        \n",
    "        for COV in classSpecificCOV:\n",
    "            estimator.fit(COV)\n",
    "            mean = estimator.estimate_\n",
    "            means.append(mean)\n",
    "        return means\n",
    "    \n",
    "    def train(self, COVtrain, Ytrain):        \n",
    "        classSpecificCOV = self.separate_classes(COVtrain, Ytrain)\n",
    "        means = self.calculate_means(classSpecificCOV)\n",
    "        self.means[0] = means[0]\n",
    "        self.means[1] = means[1]\n",
    "    \n",
    "    def frob_distance(self, matrix1, matrix2):\n",
    "        return np.linalg.norm(matrix1-matrix2, ord = 'fro')\n",
    "    \n",
    "    def predict(self, COVtest):\n",
    "        N = COVtest.shape[0]\n",
    "        prediction = np.empty((N, 1))\n",
    "        \n",
    "        for i in range(N):\n",
    "            dist = []\n",
    "            trial = COVtest[i]\n",
    "            for mean in self.means:\n",
    "                if self.Rmethod is None:\n",
    "                    dist.append(self.frob_distance(trial, mean))\n",
    "                else:\n",
    "                    dist.append(self.Rmethod.dist(trial, mean))\n",
    "            \n",
    "            prediction[i] = dist.index(min(dist))\n",
    "        return prediction\n",
    "    \n",
    "    def score(self, prediction, Ytest):\n",
    "        N = Ytest.shape[0]\n",
    "        error = 0\n",
    "        for i in range(N):\n",
    "            if prediction[i]!=Ytest[i]:\n",
    "                error+=1\n",
    "        return 100*(1-error/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubjectsCOV1, SubjectsY1 = pickle.load(open('datasets/54COV7Sess01.pickle','rb'))\n",
    "SubjectsCOV2, SubjectsY2 = pickle.load(open('datasets/54COV7Sess02.pickle','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject-dependent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_clf = MDM(20, 'Euclidean')\n",
    "a_clf = MDM(20, 'AIRM')\n",
    "l_clf = MDM(20, 'LEM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(COV, Y, k):\n",
    "    N = len(Y)\n",
    "    foldsize = int(N/k)\n",
    "    \n",
    "    c_acc = []\n",
    "    a_acc = []\n",
    "    l_acc = []\n",
    "    m_acc = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        testCOV = COV[i*foldsize:(i+1)*foldsize]\n",
    "        testY = Y[i*foldsize:(i+1)*foldsize]\n",
    "        \n",
    "        \n",
    "        trainCOV = np.concatenate((COV[:i*foldsize],COV[(i+1)*foldsize:]), axis=0) \n",
    "        trainY = np.concatenate((Y[:i*foldsize],Y[(i+1)*foldsize:]), axis=0)\n",
    "\n",
    "        c_clf.train(trainCOV, trainY)\n",
    "        c_pred = c_clf.predict(testCOV)\n",
    "        c_res = c_clf.score(c_pred, testY)\n",
    "        \n",
    "        a_clf.train(trainCOV, trainY)\n",
    "        a_pred = a_clf.predict(testCOV)\n",
    "        a_res = a_clf.score(a_pred, testY)\n",
    "        \n",
    "        l_clf.train(trainCOV, trainY)\n",
    "        l_pred = l_clf.predict(testCOV)\n",
    "        l_res = l_clf.score(l_pred, testY)\n",
    "        \n",
    "       \n",
    "        \n",
    "        preds = np.column_stack((c_pred, a_pred, l_pred)).astype('int8')\n",
    "        \n",
    "        majority = np.empty(len(preds), dtype = 'int8')\n",
    "        \n",
    "        for j in range(len(preds)):\n",
    "            majority[j] = np.argmax(np.bincount(preds[j]))\n",
    "        \n",
    "        m_res = c_clf.score(majority, testY)\n",
    "        \n",
    "        c_acc.append(c_res)\n",
    "        a_acc.append(a_res)\n",
    "        l_acc.append(l_res)\n",
    "        m_acc.append(m_res)\n",
    "    \n",
    "    return sum(c_acc)/len(c_acc), sum(a_acc)/len(a_acc), sum(l_acc)/len(l_acc), sum(m_acc)/len(m_acc)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_dependent(SubjectsCOV, SubjectsY, k):\n",
    "    df = pd.DataFrame(index=list(range(1, 55))+['Average', 'p-values'], columns=['Euclidean distance', 'AIRM distance', 'LEM distance', 'Majority Vote'])\n",
    "    \n",
    "    c_results = [] \n",
    "    a_results = []\n",
    "    l_results = []\n",
    "    m_results = []\n",
    "    \n",
    "    for i in range(len(SubjectsCOV)):\n",
    "        COVi = SubjectsCOV[i]\n",
    "        Yi = SubjectsY[i]\n",
    "\n",
    "        c_acc, a_acc, l_acc, m_acc = cross_validate(COVi, Yi, k)\n",
    "        c_results.append(c_acc)\n",
    "        a_results.append(a_acc)\n",
    "        l_results.append(l_acc)\n",
    "        m_results.append(m_acc)\n",
    "    \n",
    "    c_results.append(sum(c_results)/len(c_results))\n",
    "    \n",
    "    a_results.append(sum(a_results)/len(a_results))\n",
    "    _, pval = wilcoxon(c_results[:-1], a_results[:-1], alternative='less')\n",
    "    a_results.append(pval)\n",
    "                     \n",
    "    l_results.append(sum(l_results)/len(l_results))\n",
    "    _, pval = wilcoxon(c_results[:-1], l_results[:-1], alternative='less')\n",
    "    l_results.append(pval)\n",
    "    \n",
    "    m_results.append(sum(m_results)/len(m_results))\n",
    "    _, pval = wilcoxon(c_results[:-1], m_results[:-1], alternative='less')\n",
    "    m_results.append(pval)\n",
    "    \n",
    "    df['Euclidean distance'] = c_results + [None]\n",
    "    df['AIRM distance'] = a_results\n",
    "    df['LEM distance'] = l_results\n",
    "    df['Majority Vote'] = m_results\n",
    "    \n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = subject_dependent(SubjectsCOV1, SubjectsY1, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = subject_dependent(SubjectsCOV2, SubjectsY2, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'results/MDM/sess01_dependent.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(df1, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'results/MDM/sess02_dependent.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(df2, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subject-Independent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subject_independent(SubjectsCOV, SubjectsY):\n",
    "    df = pd.DataFrame(index=list(range(1, 55))+['Average', 'p-values'], columns=['Euclidean distance', 'AIRM distance', 'LEM distance', 'Majority Vote'])\n",
    "    \n",
    "    c_results = [] #very sloppy coding, did not prioritize clean code\n",
    "    a_results = []\n",
    "    l_results = []\n",
    "    m_results = []\n",
    "    \n",
    "    for i in range(len(SubjectsCOV)):\n",
    "        SC = deepcopy(SubjectsCOV)\n",
    "        SY = deepcopy(SubjectsY)\n",
    "            \n",
    "        testCOV = SC.pop(i)\n",
    "        testY = SY.pop(i)\n",
    "            \n",
    "        trainCOV = None\n",
    "        trainY = None\n",
    "            \n",
    "        for j in range(len(SubjectsCOV)-1):\n",
    "            if trainCOV is None:\n",
    "                trainCOV = SC[j]\n",
    "                trainY = SY[j]\n",
    "            else:\n",
    "                trainCOV = np.concatenate((trainCOV, SC[j]))\n",
    "                trainY = np.concatenate((trainY, SY[j]))\n",
    "\n",
    "        c_clf.train(trainCOV, trainY)\n",
    "        c_pred = c_clf.predict(testCOV)\n",
    "        c_res = c_clf.score(c_pred, testY)\n",
    "        \n",
    "        a_clf.train(trainCOV, trainY)\n",
    "        a_pred = a_clf.predict(testCOV)\n",
    "        a_res = a_clf.score(a_pred, testY)\n",
    "        \n",
    "        l_clf.train(trainCOV, trainY)\n",
    "        l_pred = l_clf.predict(testCOV)\n",
    "        l_res = l_clf.score(l_pred, testY)\n",
    "        \n",
    "        preds = np.column_stack((c_pred, a_pred, l_pred)).astype('int8')\n",
    "        \n",
    "        majority = np.empty(len(preds), dtype = 'int8')\n",
    "        \n",
    "        for j in range(len(preds)):\n",
    "            majority[j] = np.argmax(np.bincount(preds[j]))\n",
    "        \n",
    "        m_res = c_clf.score(majority, testY)\n",
    "    \n",
    "        c_results.append(c_res)\n",
    "        a_results.append(a_res)\n",
    "        l_results.append(l_res)\n",
    "        m_results.append(m_res)\n",
    "    \n",
    "    c_results.append(sum(c_results)/len(c_results))\n",
    "    \n",
    "    a_results.append(sum(a_results)/len(a_results))\n",
    "    _, pval = wilcoxon(c_results[:-1], a_results[:-1], alternative='less')\n",
    "    a_results.append(pval)\n",
    "                     \n",
    "    l_results.append(sum(l_results)/len(l_results))\n",
    "    _, pval = wilcoxon(c_results[:-1], l_results[:-1], alternative='less')\n",
    "    l_results.append(pval)\n",
    "    \n",
    "    m_results.append(sum(m_results)/len(m_results))\n",
    "    _, pval = wilcoxon(c_results[:-1], m_results[:-1], alternative='less')\n",
    "    m_results.append(pval)\n",
    "    \n",
    "    df['Euclidean distance'] = c_results + [None]\n",
    "    df['AIRM distance'] = a_results\n",
    "    df['LEM distance'] = l_results\n",
    "    df['Majority Vote'] = m_results\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_i = subject_independent(SubjectsCOV1, SubjectsY1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1_i = df1_i.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'results/MDM/sess01_7_independent.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(df1_i, outfile)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Session 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_i = subject_independent(SubjectsCOV2, SubjectsY2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_i = df2_i.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'results/MDM/sess02_7_independent.pickle'\n",
    "outfile = open(filename,'wb')\n",
    "pickle.dump(df2_i, outfile)\n",
    "outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
